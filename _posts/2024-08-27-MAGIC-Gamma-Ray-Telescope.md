---
layout: post
title:  "Binary classification: MAGIC Gamma-Ray Telescope"
date:   2024-08-27 18:26:57 -0600
categories: jekyll update
---

<img src="/assets/images/magic_gamma_ray_telescope/magic-anochece-dlopez_1920.jpg">

The MAGIC telescopes at the Roque de los Muchachos Observatory. Credit: Daniel López/IAC.<br>
<a href="url">https://www.iac.es/en/outreach/news/magic-telescopes-test-quantum-structure-space-time</a>


## Gamma-ray sources and detectors

Gamma rays are the most energetic form of electromagnetic radiation. Typically, the bottom end of the gamma ray band is set at ~0.5 MeV, the rest mass energy of an electron.  

Several types of objects in the Universe are known to be sources of gamma rays: gamma-ray bursts, supernova remnants, active galactic nuclei, and pulsars among others. Luckily, gamma rays cannot traverse the Earth's atmosphere and reach the ground; we say that the atmosphere is *opaque* to gamma rays. Otherwise, life on Earth would not be possible. We don't want a gamma-ray burst pointing directly at us, however: such an amount of gamma radiation would deplete the ozone layer with catastrophic consequences to life. Scientist have even analyzed the possibility that the Ordovician extinction (450 million years ago) was triggered by such an event; you can read more [here](https://astrobiology.nasa.gov/news/how-deadly-would-a-nearby-gamma-ray-burst-be/).

How do we go about detecting gamma-ray sources if gamma rays cannot reach the surface of the Earth? The first option is to take our gamma-ray telescopes to space. A very successful space-borne gamma-ray mission, launched in 2008, is NASA's [Fermi Gamma-Ray Telescope](https://fermi.gsfc.nasa.gov/).

However, we face a problem when we want to detect the most energetic sources, that emit gamma rays with energies in the ~TeV range ($$1$$ TeV = $$10^{12}$$ eV). At those energies, the flux of incoming photons is so low that we would need a huge telescope in space to detect enough of them. This is too expensive and impractical.

But there's a alternative. When an energetic gamma ray reaches the top of the Earth's atmosphere, it interacts with the atmosphere's components to produce new particles (less energetic photons and electron-positron pairs), that in time create new particles, etc. We say that the primary gamma ray triggers an *electromagnetic cascade* in the atmosphere. As the secondary charged particles move (very fast) through the atmosphere, they emit light in the blue to ultraviolet range, called Cherenkov radiation. This Cherenkov light can be collected at ground level with detectors made up of arrays of mirrors. Each cascade leaves a distinct image on the detector; the analysis of this image allows to reconstruct the energy and arrival direction of the primary photon. You can read more about this technique [here](https://arxiv.org/abs/2401.04460v1)

Gamma-ray detectors based on this technique are called *Imaging Atmospheric Cherenkov Telescopes* (IACT). There are a few IACT currently operating, including [HESS](https://www.mpi-hd.mpg.de/hfm/HESS/),  [VERITAS](https://veritas.sao.arizona.edu/), and [MAGIC](https://magic.mpp.mpg.de/). 

There's still one problem to address: cosmic rays (mainly protons and other nuclei) also trigger electromagnetic cascades in the atmosphere. In a gamma-ray detector, this is background noise that must be filtered. The cascades initiated by a photon and a proton of the same energy develop differently in the atmosphere and thus leave different images on the detectors; see for example Figure 1 of [this paper](https://arxiv.org/html/2401.04460v1/#bib.bib11). These differences can be used to separate signal from noise.

Here, we will train a logistic regression classifier to separate events triggered by gamma rays and protons based on the characteristics of the images left by the cascades on the detector. We'll use a set of synthetic data generated by the MonteCarlo code [*Corsika*](https://www.iap.kit.edu/corsika) to simulate registration of high-energy gamma rays in the Major Atmospheric Gamma-Ray Imaging Cherenkov (MAGIC) Gamma Telescope.

## Description of the dataset

The dataset is available for download at the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope). It was created by R. Bock and donated on 4/30/2007. <br>
**Citation**: Bock, R. (2007). MAGIC Gamma Telescope. UCI Machine Learning Repository, <a href="url">https://doi.org/10.24432/C52C8B</a>.

It contains 11 variables: 10 features plus the target variable. A short description of the features follows; the image below shows a sketch of the cascade image on the detector, indicating some relevant geometric parameters used as features.

The features available for classification are:

- **fLength**: major axis of the ellipse [mm]
- **fWidth**: minor axis of the ellipse [mm]
- **fSize**: 10-log of sum of content of all pixels [#photons]
- **fConc**: ratio of sum of two highest pixels over **fSize** [dimensionless]
- **fConc1**: ratio of highest pixel over **fSize** [dimensionless]
- **fAsym**: distance from highest pixel to center, projected onto major axis [mm]
- **fM3Long**: 3rd root of third moment along major axis [mm]
- **fM3Trans**: 3rd root of third moment along minor axis [mm]
- **fAlpha**: angle of major axis with vector to origin [deg]
- **fDist**: distance from origin to center of ellipse [mm]

The target variable is binary:

- **class**: gamma (*g*, signal), hadron (*h*, background) (hadrons are particles made of quarks, a proton is a hadron)

<img src="/assets/images/magic_gamma_ray_telescope/Cherenkov-telescope-sketch-and-definition-of-some-image-parameters_2.png">

Sketch and definition of some image parameters, the inset is a simulated event in MAGIC.</br> Image from R. K. Bock & W. Wittek, <i>Multidimensional event classification in images from gamma-ray air showers</i>, <a href="url">https://www.ippp.dur.ac.uk/Workshops/02/statistics/proceedings/bock.pdf</a>.

## Import packages


```python
# Data manipulation
import numpy as np
import pandas as pd

# Plotting
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns

# Data pre-processing
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# Logistic regression
from sklearn.linear_model import LogisticRegression

# PCA
from sklearn.decomposition import PCA

# Metrics to evaluate the model
from sklearn import metrics
from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve,recall_score
from sklearn import tree

# To calculate the Variance Inflation Factor (VIF)
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Package to easily import datasets from the UC Irvine Machine Learning Repository into scripts and notebooks.
# See https://github.com/uci-ml-repo/ucimlrepo
from ucimlrepo import fetch_ucirepo 
```

Let's set the maximum number of displayed columns and rows  for `pandas` DafaFrames:


```python
# Removes the limit for the number of displayed columns
pd.set_option("display.max_columns", None)
# Sets the limit for the number of displayed rows
pd.set_option("display.max_rows", 300)
```

## Load the dataset

It can be retrieved with the `fetch_ucirepo()` method in `ucimlrepo`. You need to provide either a dataset ID or name as keyword (named) arguments:

- **id**: dataset ID for UCI ML Repository
- **name**: dataset name, or substring of name

For the MAGIC dataset, `id=159` and `name='MAGIC Gamma Telescope'`.

Let's retrieve the dataset. The attribute `data.original` returns a DataFrame consisting of all IDs, features, and targets.


```python
magic_gamma_telescope = fetch_ucirepo(id=159) # alternatively: fetch_ucirepo(name='MAGIC Gamma Telescope')
```


```python
data = magic_gamma_telescope.data.original
```

## Overview of the dataset

Let's check the size of the dataset:


```python
data.shape
```




    (19020, 11)



There are 19,020 observations (rows) of 11 variables (10 features + the target variable).

Let's retrieve some random observations to take a look:


```python
data.sample(n=7)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fLength</th>
      <th>fWidth</th>
      <th>fSize</th>
      <th>fConc</th>
      <th>fConc1</th>
      <th>fAsym</th>
      <th>fM3Long</th>
      <th>fM3Trans</th>
      <th>fAlpha</th>
      <th>fDist</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1879</th>
      <td>38.6090</td>
      <td>25.2966</td>
      <td>2.7749</td>
      <td>0.2603</td>
      <td>0.1570</td>
      <td>-46.3399</td>
      <td>-29.9227</td>
      <td>16.7860</td>
      <td>10.9353</td>
      <td>166.4060</td>
      <td>g</td>
    </tr>
    <tr>
      <th>11819</th>
      <td>32.5853</td>
      <td>16.9986</td>
      <td>2.7555</td>
      <td>0.3494</td>
      <td>0.1923</td>
      <td>-6.8633</td>
      <td>23.0946</td>
      <td>7.1595</td>
      <td>6.5570</td>
      <td>160.1170</td>
      <td>g</td>
    </tr>
    <tr>
      <th>19007</th>
      <td>115.2640</td>
      <td>14.0075</td>
      <td>2.8540</td>
      <td>0.7544</td>
      <td>0.4136</td>
      <td>-88.2076</td>
      <td>-117.4860</td>
      <td>8.4777</td>
      <td>28.0100</td>
      <td>336.9910</td>
      <td>h</td>
    </tr>
    <tr>
      <th>5321</th>
      <td>63.8088</td>
      <td>18.3460</td>
      <td>2.9180</td>
      <td>0.3092</td>
      <td>0.1552</td>
      <td>43.7516</td>
      <td>65.9962</td>
      <td>-8.3016</td>
      <td>8.9660</td>
      <td>225.8190</td>
      <td>g</td>
    </tr>
    <tr>
      <th>4437</th>
      <td>109.0430</td>
      <td>22.2986</td>
      <td>3.1284</td>
      <td>0.1964</td>
      <td>0.1060</td>
      <td>94.4585</td>
      <td>105.8000</td>
      <td>17.1356</td>
      <td>0.6580</td>
      <td>261.2200</td>
      <td>g</td>
    </tr>
    <tr>
      <th>18725</th>
      <td>96.4519</td>
      <td>18.3664</td>
      <td>3.1219</td>
      <td>0.3696</td>
      <td>0.1955</td>
      <td>31.7630</td>
      <td>61.8269</td>
      <td>-21.3187</td>
      <td>7.4816</td>
      <td>353.7327</td>
      <td>h</td>
    </tr>
    <tr>
      <th>3578</th>
      <td>21.8031</td>
      <td>9.7761</td>
      <td>2.2672</td>
      <td>0.5946</td>
      <td>0.3162</td>
      <td>5.1895</td>
      <td>-16.8994</td>
      <td>-10.6724</td>
      <td>23.2813</td>
      <td>110.3290</td>
      <td>g</td>
    </tr>
  </tbody>
</table>
</div>



Everything looks good...

Let's check now for missing data and the column types:


```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 19020 entries, 0 to 19019
    Data columns (total 11 columns):
     #   Column    Non-Null Count  Dtype  
    ---  ------    --------------  -----  
     0   fLength   19020 non-null  float64
     1   fWidth    19020 non-null  float64
     2   fSize     19020 non-null  float64
     3   fConc     19020 non-null  float64
     4   fConc1    19020 non-null  float64
     5   fAsym     19020 non-null  float64
     6   fM3Long   19020 non-null  float64
     7   fM3Trans  19020 non-null  float64
     8   fAlpha    19020 non-null  float64
     9   fDist     19020 non-null  float64
     10  class     19020 non-null  object 
    dtypes: float64(10), object(1)
    memory usage: 1.6+ MB
    

There are no missing values and the data types of all variables are those expected from their descriptions. In particular, all features are numerical and of type `float64` and the target variable is of type `object` (a string).

Let's check now for duplicated records:


```python
data.duplicated().sum()
```




    115



There are 115 duplicated records. Let's take a closer look at them:


```python
is_duplicated = data.duplicated(keep=False)
data.loc[is_duplicated].sort_values(by='fLength').head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fLength</th>
      <th>fWidth</th>
      <th>fSize</th>
      <th>fConc</th>
      <th>fConc1</th>
      <th>fAsym</th>
      <th>fM3Long</th>
      <th>fM3Trans</th>
      <th>fAlpha</th>
      <th>fDist</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15221</th>
      <td>12.9176</td>
      <td>11.3596</td>
      <td>2.1123</td>
      <td>0.7413</td>
      <td>0.3900</td>
      <td>15.0388</td>
      <td>-5.6768</td>
      <td>-11.5638</td>
      <td>64.933</td>
      <td>227.1070</td>
      <td>h</td>
    </tr>
    <tr>
      <th>18512</th>
      <td>12.9176</td>
      <td>11.3596</td>
      <td>2.1123</td>
      <td>0.7413</td>
      <td>0.3900</td>
      <td>15.0388</td>
      <td>-5.6768</td>
      <td>-11.5638</td>
      <td>64.933</td>
      <td>227.1070</td>
      <td>h</td>
    </tr>
    <tr>
      <th>14954</th>
      <td>12.9801</td>
      <td>10.8815</td>
      <td>2.4175</td>
      <td>0.7457</td>
      <td>0.4723</td>
      <td>-13.6970</td>
      <td>6.0371</td>
      <td>-7.0019</td>
      <td>30.803</td>
      <td>78.2618</td>
      <td>h</td>
    </tr>
    <tr>
      <th>18223</th>
      <td>12.9801</td>
      <td>10.8815</td>
      <td>2.4175</td>
      <td>0.7457</td>
      <td>0.4723</td>
      <td>-13.6970</td>
      <td>6.0371</td>
      <td>-7.0019</td>
      <td>30.803</td>
      <td>78.2618</td>
      <td>h</td>
    </tr>
    <tr>
      <th>15898</th>
      <td>13.0287</td>
      <td>10.9544</td>
      <td>2.2000</td>
      <td>0.7571</td>
      <td>0.4511</td>
      <td>-14.0985</td>
      <td>5.7807</td>
      <td>-10.1748</td>
      <td>64.870</td>
      <td>182.9800</td>
      <td>h</td>
    </tr>
    <tr>
      <th>13389</th>
      <td>13.0287</td>
      <td>10.9544</td>
      <td>2.2000</td>
      <td>0.7571</td>
      <td>0.4511</td>
      <td>-14.0985</td>
      <td>5.7807</td>
      <td>-10.1748</td>
      <td>64.870</td>
      <td>182.9800</td>
      <td>h</td>
    </tr>
    <tr>
      <th>16656</th>
      <td>14.7912</td>
      <td>11.7955</td>
      <td>2.3075</td>
      <td>0.6749</td>
      <td>0.4557</td>
      <td>1.3533</td>
      <td>4.7675</td>
      <td>-9.0611</td>
      <td>62.250</td>
      <td>62.5245</td>
      <td>h</td>
    </tr>
    <tr>
      <th>12635</th>
      <td>14.7912</td>
      <td>11.7955</td>
      <td>2.3075</td>
      <td>0.6749</td>
      <td>0.4557</td>
      <td>1.3533</td>
      <td>4.7675</td>
      <td>-9.0611</td>
      <td>62.250</td>
      <td>62.5245</td>
      <td>h</td>
    </tr>
    <tr>
      <th>17123</th>
      <td>16.7566</td>
      <td>11.3063</td>
      <td>2.3766</td>
      <td>0.5840</td>
      <td>0.3550</td>
      <td>0.0000</td>
      <td>0.1543</td>
      <td>6.7419</td>
      <td>48.504</td>
      <td>117.6360</td>
      <td>h</td>
    </tr>
    <tr>
      <th>12500</th>
      <td>16.7566</td>
      <td>11.3063</td>
      <td>2.3766</td>
      <td>0.5840</td>
      <td>0.3550</td>
      <td>0.0000</td>
      <td>0.1543</td>
      <td>6.7419</td>
      <td>48.504</td>
      <td>117.6360</td>
      <td>h</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Check if any of the duplicates correspond to class 'g'
data.loc[is_duplicated]['class'].isin(['g']).sum()
```




    0



>  - All duplicated records correspond to events classified as hadrons.
>  - All duplicated records have exactly one duplicate only.

I'll remove the duplicates, keeping the first of the duplicated entries:


```python
data_duplicates = data.copy(deep=True) # Keep a copy of the data before removing duplicates
```


```python
data.drop_duplicates(keep='first', inplace=True, ignore_index=True)
data.duplicated().sum()
```




    0



Let's get the statistical summary of the data, beginning with the numerical data (in this case, all the features).


```python
data.describe().T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fLength</th>
      <td>18905.0</td>
      <td>53.161416</td>
      <td>42.259789</td>
      <td>4.2835</td>
      <td>24.3597</td>
      <td>37.1295</td>
      <td>69.9754</td>
      <td>334.1770</td>
    </tr>
    <tr>
      <th>fWidth</th>
      <td>18905.0</td>
      <td>22.145872</td>
      <td>18.300664</td>
      <td>0.0000</td>
      <td>11.8742</td>
      <td>17.1438</td>
      <td>24.7124</td>
      <td>256.3820</td>
    </tr>
    <tr>
      <th>fSize</th>
      <td>18905.0</td>
      <td>2.824643</td>
      <td>0.472377</td>
      <td>1.9413</td>
      <td>2.4771</td>
      <td>2.7400</td>
      <td>3.1011</td>
      <td>5.3233</td>
    </tr>
    <tr>
      <th>fConc</th>
      <td>18905.0</td>
      <td>0.380247</td>
      <td>0.182709</td>
      <td>0.0131</td>
      <td>0.2358</td>
      <td>0.3540</td>
      <td>0.5035</td>
      <td>0.8930</td>
    </tr>
    <tr>
      <th>fConc1</th>
      <td>18905.0</td>
      <td>0.214560</td>
      <td>0.110384</td>
      <td>0.0003</td>
      <td>0.1285</td>
      <td>0.1964</td>
      <td>0.2850</td>
      <td>0.6752</td>
    </tr>
    <tr>
      <th>fAsym</th>
      <td>18905.0</td>
      <td>-4.177867</td>
      <td>59.010059</td>
      <td>-457.9161</td>
      <td>-20.4791</td>
      <td>4.0629</td>
      <td>24.1335</td>
      <td>575.2407</td>
    </tr>
    <tr>
      <th>fM3Long</th>
      <td>18905.0</td>
      <td>10.618826</td>
      <td>50.900687</td>
      <td>-331.7800</td>
      <td>-12.7693</td>
      <td>15.3380</td>
      <td>35.8694</td>
      <td>238.3210</td>
    </tr>
    <tr>
      <th>fM3Trans</th>
      <td>18905.0</td>
      <td>0.259364</td>
      <td>20.775268</td>
      <td>-205.8947</td>
      <td>-10.8358</td>
      <td>0.7500</td>
      <td>10.9489</td>
      <td>179.8510</td>
    </tr>
    <tr>
      <th>fAlpha</th>
      <td>18905.0</td>
      <td>27.551644</td>
      <td>26.083055</td>
      <td>0.0000</td>
      <td>5.5164</td>
      <td>17.5330</td>
      <td>45.7040</td>
      <td>90.0000</td>
    </tr>
    <tr>
      <th>fDist</th>
      <td>18905.0</td>
      <td>193.712554</td>
      <td>74.685712</td>
      <td>1.2826</td>
      <td>142.2690</td>
      <td>191.8320</td>
      <td>240.4090</td>
      <td>495.5610</td>
    </tr>
  </tbody>
</table>
</div>



A few observations and sanity checks:
- The distributions of `fWidth` and `fLength` are right-skewed.
- The minimum of `fWidth` is zero. This configuration could be possible, I guess.
- `fAsym` takes both negative and positive values; this probably cooresponds to the highest pixel being on one side or the other with respect to the center of the ellipse. 
- Ratios (`fConc`, `fConc1`) take values below 1, as expected.
- The angle `fAlpha` is in the expected range, too ($$0^\circ \leq$$ `fAlpha` $$\leq 90^\circ$$ ).

Finally, let's get the statistical summary for the target variable:


```python
data.describe(include=["object"]).T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>unique</th>
      <th>top</th>
      <th>freq</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>class</th>
      <td>18905</td>
      <td>2</td>
      <td>g</td>
      <td>12332</td>
    </tr>
  </tbody>
</table>
</div>



As expected, there are only two classes. The most represented class is `class = g` (gamma-rays) with 12,332 out of the 18,905 events (~65%) after removing duplicates.

## Exploratory Data Analysis

Let's start by exploring the distribution of the features separated by class, to gain some insight into which of them could be the most relevant to discriminate photons from hadrons. 

We can begin by taking a look at the mean and median of the features for each class: 


```python
data.groupby(['class']).agg(['mean','median']).T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class</th>
      <th>g</th>
      <th>h</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">fLength</th>
      <th>mean</th>
      <td>43.654539</td>
      <td>70.997838</td>
    </tr>
    <tr>
      <th>median</th>
      <td>34.558000</td>
      <td>47.911600</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fWidth</th>
      <th>mean</th>
      <td>18.592698</td>
      <td>28.812195</td>
    </tr>
    <tr>
      <th>median</th>
      <td>17.053300</td>
      <td>17.397200</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fSize</th>
      <th>mean</th>
      <td>2.784021</td>
      <td>2.900856</td>
    </tr>
    <tr>
      <th>median</th>
      <td>2.704800</td>
      <td>2.798700</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fConc</th>
      <th>mean</th>
      <td>0.383641</td>
      <td>0.373880</td>
    </tr>
    <tr>
      <th>median</th>
      <td>0.352600</td>
      <td>0.357100</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fConc1</th>
      <th>mean</th>
      <td>0.215048</td>
      <td>0.213645</td>
    </tr>
    <tr>
      <th>median</th>
      <td>0.195000</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fAsym</th>
      <th>mean</th>
      <td>3.236653</td>
      <td>-18.088693</td>
    </tr>
    <tr>
      <th>median</th>
      <td>6.638150</td>
      <td>-1.476100</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fM3Long</th>
      <th>mean</th>
      <td>17.809413</td>
      <td>-2.871864</td>
    </tr>
    <tr>
      <th>median</th>
      <td>16.912650</td>
      <td>11.134400</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fM3Trans</th>
      <th>mean</th>
      <td>0.190873</td>
      <td>0.387865</td>
    </tr>
    <tr>
      <th>median</th>
      <td>1.328000</td>
      <td>0.420900</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fAlpha</th>
      <th>mean</th>
      <td>18.784309</td>
      <td>44.000568</td>
    </tr>
    <tr>
      <th>median</th>
      <td>9.708150</td>
      <td>43.407000</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">fDist</th>
      <th>mean</th>
      <td>190.229712</td>
      <td>200.246922</td>
    </tr>
    <tr>
      <th>median</th>
      <td>188.120000</td>
      <td>199.835000</td>
    </tr>
  </tbody>
</table>
</div>



Some features (`fAsym`, `fAlpha`) show significantly different values of the mean and median across classes. Let's explore this further with some plots.

#### Boxplots


```python
# A list with the names of the features
features = list(data.drop('class', axis=1).columns) 
```


```python
# Produce one boxplot per feature arranged in a grid
n_plots = len(features)
n_cols  = 3
n_rows  = n_plots // n_cols + 1

fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15,18))

for feature, ax in zip(features, axs.flatten()):
    sns.boxplot(data=data, y=feature, x='class', showmeans=True, ax=ax)

# Remove empty plots
[fig.delaxes(ax) for ax in axs.flatten() if not ax.has_data()] 

plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_50_0.png">
    


- Most features show statistical outliers. I'll keep these outliers for the moment.
- Some features -  `fLength`, `fWidth` and `fSize`, for example - show signficantly right-skewed distributions.
- Other are quite symmetric, such as `fAsym` and `fConc`.
- The distribution of `fAlpha` is very different across classes. 

#### Histograms

Let's explore the feature distributions per class further, now from histograms. <br>
The histogram bars are normalized such that their heights add up to 1 (`stat='proportion'`) independently for each class (`common_norm=False`).


```python
# Produce one histogram per feature arranged in a grid
fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15,18))

for feature, ax in zip(features, axs.flatten()):
    sns.histplot(data=data, x=feature, hue='class', ax=ax, stat='proportion', common_norm=False)

# Remove empty plots
[fig.delaxes(ax) for ax in axs.flatten() if not ax.has_data()] 

plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_54_0.png">
    


- Some features take a wider range of values for hadrons, in particular more extended tails to the right (`fLength`, `fWidth`), to the left (`fM3Long`) or both (`fM3Trans`).
- Indeed, the distribution of `fAlpha` is very different for both classes. It is uniform for hadrons, but strongly skewed to the right for gamma rays.
- Other features such as `fConc1` and `fConc`, show similar distributions for hadrons and gamma rays. These features may be less useful to distinguish between classes.

#### Colinearity and multicolinearity between features

Let's explore possible colinearities and multicolinearities between features. In algorithms involving linear regression, colinearity and multicolinearity cause the standard errors of the coefficients to increase and may make the coefficients unstable. If we want to analyze feature importance in logistic regression, then we must try to remove multicolinearity.

To look at the degree of linear correlation between pairs of features, I'll calculate and visualize the correlation matrix for the pairwise Pearson correlation coefficient.

To look for multicolinearity, I'll calculate the **Variance Inflation Factor (VIF)**. The VIF measures how much the variance of a regression coefficient increases due to multicollinearity in a multiple regression model. For a coefficient $$\beta_j$$, the VIF is given by

<center>$$ {\rm{VIF}}_j = \dfrac{1}{1 - R_j^2}$$, </center>

where $$R_j^2$$ is the coefficient of determination for the regression of feature $$X_j$$ on the other features (not including the target variable). VIFs are always > 1. As a rule of thumb, it is suggested that VIF > 5 indicates strong multicolinearity (sometimes VIF > 10 is used) .

I define an auxiliary DataFrame only for the features:


```python
features_df = data.drop(columns='class')
```

### - Correlation matrix


```python
plt.figure(figsize=(10, 5))
sns.heatmap(features_df.corr(), annot=True, vmin=-1, vmax=1, fmt=".2f", cmap="Spectral")
plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_61_0.png">
    


Some features are linearly correlated:
- `fConc` and `fConc1` are almost perfectly correlated (correlation coefficient 0.98).
- `fSize` is strongly negatively correlated with `fConc` (-0.85) and `fConc1` (-0.81).
- `fLength`, `fWidth` and `fSize` are all  positively correlated with correlation coefficient values 0.70-0.77.

Let's take a look at the plots of each of these features vs. the others:


```python
correlated_features = ['fConc', 'fConc1', 'fSize', 'fWidth', 'fLength']

sns.pairplot(data, vars=correlated_features, corner=False, kind='scatter')
plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_64_0.png">
    


- Indeed, we see that `fConc` and `fConc1` are clearly linearly correlated.
- `fWidth` and `fLength` also show linear dependence, but with a larger dispersion.
-  `fConc` (and `fConc1`) and `fSize` are also correlated although they show an inverse dependency, `fConc/fConc1 ~ 1/fSize`; this is expected from their definition. 

### - Variance Inflation Factor (VIF)

Let's define a convenience function that returns the VIF for each of the input features. The method `variance_inflation_factor` to calculate the VIF is included in the `statsmodels` library. 


```python
# Function to calculate VIF. The input is a DataFrame with the features in the columns.
def calculate_vif(features):
    vif = pd.DataFrame() # initialize empty DataFrame to store results
    vif["feature"] = features.columns

    # Calculate VIF for each feature and populate the DataFrame
    vif["VIF"] = [
        variance_inflation_factor(features.values, i) for i in range(len(features.columns))
    ]
    return vif
```

Let's calculate the VIF and sort the features in descending order by VIF:


```python
calculate_vif(features_df).sort_values(by='VIF', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>fConc</td>
      <td>114.828383</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fConc1</td>
      <td>102.349097</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fSize</td>
      <td>22.461761</td>
    </tr>
    <tr>
      <th>9</th>
      <td>fDist</td>
      <td>10.576926</td>
    </tr>
    <tr>
      <th>0</th>
      <td>fLength</td>
      <td>8.258849</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fWidth</td>
      <td>7.552899</td>
    </tr>
    <tr>
      <th>8</th>
      <td>fAlpha</td>
      <td>2.557689</td>
    </tr>
    <tr>
      <th>6</th>
      <td>fM3Long</td>
      <td>1.287655</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fAsym</td>
      <td>1.267047</td>
    </tr>
    <tr>
      <th>7</th>
      <td>fM3Trans</td>
      <td>1.002765</td>
    </tr>
  </tbody>
</table>
</div>



`fConc` and `fConc1` show very large VIF; this was expected since these two features are almost perfectly linearly correlated. Let's remove the feature with the highest VIF of the two, `fConc`, and check the VIF again:


```python
cols_2_drop = ['fConc']
calculate_vif(features_df.drop(columns=cols_2_drop)).sort_values(by='VIF', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>fSize</td>
      <td>21.078580</td>
    </tr>
    <tr>
      <th>8</th>
      <td>fDist</td>
      <td>10.566476</td>
    </tr>
    <tr>
      <th>0</th>
      <td>fLength</td>
      <td>8.145738</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fWidth</td>
      <td>7.466251</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fConc1</td>
      <td>5.959752</td>
    </tr>
    <tr>
      <th>7</th>
      <td>fAlpha</td>
      <td>2.517479</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fM3Long</td>
      <td>1.281001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fAsym</td>
      <td>1.266966</td>
    </tr>
    <tr>
      <th>6</th>
      <td>fM3Trans</td>
      <td>1.002758</td>
    </tr>
  </tbody>
</table>
</div>



Removing `fConc` considerably decreased the VIF of `fConc1`. 

The next highest VIF corresponds to `fSize`. By definition, `fConc` and `fSize` are related. Let's see if the VIF improves removing `fSize`:


```python
cols_2_drop = ['fConc', 'fSize']
calculate_vif(features_df.drop(columns=cols_2_drop)).sort_values(by='VIF', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>fLength</td>
      <td>7.532921</td>
    </tr>
    <tr>
      <th>7</th>
      <td>fDist</td>
      <td>7.401700</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fWidth</td>
      <td>6.488117</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fConc1</td>
      <td>4.248099</td>
    </tr>
    <tr>
      <th>6</th>
      <td>fAlpha</td>
      <td>2.499947</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fAsym</td>
      <td>1.221761</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fM3Long</td>
      <td>1.194524</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fM3Trans</td>
      <td>1.002474</td>
    </tr>
  </tbody>
</table>
</div>



Removing `fSize`, the VIF for `fDist` is now below 10.

Let's try one more thing: define a new feature `aspect_ratio` as the ratio between `fWidth` and `fLength` and check the VIF with this new feature included and `fWidth` and `fLength` removed.


```python
features_df['aspect_ratio'] = features_df['fWidth']/features_df['fLength']
```


```python
cols_2_drop = ['fConc', 'fSize', 'fLength', 'fWidth']
calculate_vif(features_df.drop(columns=cols_2_drop)).sort_values(by='VIF', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>aspect_ratio</td>
      <td>5.131348</td>
    </tr>
    <tr>
      <th>0</th>
      <td>fConc1</td>
      <td>4.213366</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fDist</td>
      <td>3.789888</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fAlpha</td>
      <td>2.293906</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fM3Long</td>
      <td>1.165553</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fAsym</td>
      <td>1.162589</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fM3Trans</td>
      <td>1.001055</td>
    </tr>
  </tbody>
</table>
</div>



Now all the features have values of the VIF ~< 5. Let's hold out the names of the features we removed to later build a model without considering them:


```python
cols_2_drop_vif = ['fConc', 'fWidth', 'fLength', 'fSize']
```

## Model 1: logistic regression with VIF for feature selection

### 1) Target variable encoding

First, we encode the target variable. Gamma rays (signal) will be assigned the value 1 and hadrons (background) the value 0.


```python
dict_Class = {'g': 1, 'h':0}
```


```python
data['class_encoded'] = data['class'].map(dict_Class)
```

Now, define the target variable `Y`.


```python
Y = data['class_encoded']
```

And define the feature matrix `X` dropping the features removed during the VIF analysis:


```python
X = features_df.drop(columns=cols_2_drop_vif)
```

### 2) Training/test splitting

Now, split the data into the training and test sets, preserving the proportion of each class (`stratify = Y`). I'll hold out 30% of the observations for the test set. 


```python
random_state     = 1  # fixed for reproducibility across runs
test_train_ratio = 0.3
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_train_ratio, random_state = random_state, stratify = Y)
```


```python
X_train.shape, X_test.shape
```




    ((13233, 7), (5672, 7))



Let's check that the proportion of classes is indeed preserved in the train and test data:


```python
data['class_encoded'].value_counts(normalize=True)
```




    class_encoded
    1    0.652314
    0    0.347686
    Name: proportion, dtype: float64




```python
y_train.value_counts(normalize=True)
```




    class_encoded
    1    0.652309
    0    0.347691
    Name: proportion, dtype: float64




```python
y_test.value_counts(normalize=True)
```




    class_encoded
    1    0.652327
    0    0.347673
    Name: proportion, dtype: float64



The proportions were preserved: ~65% gamma-rays/signal (1) and ~35% hadrons/background (0).

### 3) Feature scaling

By default, the logistic regression class in `scikit-learn` applies ridge (L2) regularization to estimate the coefficients. If we want to keep the regularization, standardizing the features is advised. Standarization removes the mean and scales each feature dividing by its standard deviation.

We'll scale the features applying the `StandardScaler` class from `scikit-learn`. It is fundamental to learn the parameters of the scaler from the training data only, and then standardize the test data with the parameters learned from the training set.


```python
# Initialization of the scaler
std_sc = StandardScaler(with_mean=True, with_std=True)

# Fit_transform on training data
X_train_scaled = std_sc.fit_transform(X_train)
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)

# Transform on test data
X_test_scaled = std_sc.transform(X_test)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
```

#### 4) Model performance evaluation

Classifying a background event (h=0) as signal (g=1) is a more severe error than classifying a signal event as background.

Therefore, we will try to **minimize the number of false positives**, i.e. events classified as gamma-rays/signal (1) that are actually hadrons/background (0). <br>

This implies **maximizing the precision** of the model for class 1:

<center>$$ \rm{precision} = \dfrac{TP}{FP + TP}$$, </center>

where $$\mathrm{TP}$$ = true positives and $$\mathrm{FP}$$ = false positives.


Finally, before beginning with the classification, let's define an auxiliary function to calculate and plot an annotated confusion matrix:


```python
# Calculating and plotting annotated confusion matrix:
def calculate_plot_cm(actual, predicted):
    cm = confusion_matrix(actual, predicted)
    plt.figure(figsize=(4,4))
    
    sns.heatmap(cm, annot=True,  fmt='.0f', cbar=False, xticklabels=['0 (background)', '1 (signal)'], yticklabels=['0 (background)', '1 (signal)'])
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()
```

### 4) Fit the logistic regression model

Let's fit a logistic regression model and check its performance. As noticed before, by default L2 regularization is applied. Just to keep track of this parameter, I'll explicitly give it as an input in the class initialization (`penalty = 'l2'`). 


```python
# Fitting a logistic regression model
penalty_lg = 'l2'
lg = LogisticRegression(penalty = penalty_lg)
lg.fit(X_train_scaled, y_train)
```




<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div>




```python
# Checking the performance on the training data
y_pred_train = lg.predict(X_train_scaled)
print(classification_report(y_train, y_pred_train))
calculate_plot_cm(y_train, y_pred_train)
```

                  precision    recall  f1-score   support
    
               0       0.76      0.57      0.65      4601
               1       0.80      0.90      0.85      8632
    
        accuracy                           0.79     13233
       macro avg       0.78      0.74      0.75     13233
    weighted avg       0.78      0.79      0.78     13233
    
    


    
<img src="/assets/images/magic_gamma_ray_telescope/output_109_1.png">
    


> We got `precision = 0.80` for class 1 on the training set.


```python
# Checking the performance on the test dataset
y_pred_test = lg.predict(X_test_scaled)
print(classification_report(y_test, y_pred_test))
calculate_plot_cm(y_test, y_pred_test)
```

                  precision    recall  f1-score   support
    
               0       0.75      0.56      0.64      1972
               1       0.79      0.90      0.84      3700
    
        accuracy                           0.78      5672
       macro avg       0.77      0.73      0.74      5672
    weighted avg       0.78      0.78      0.77      5672
    
    


    
<img src="/assets/images/magic_gamma_ray_telescope/output_111_1.png">
    


> We got basically the same value of the `precision = 0.79` on the test set for class 1. The same is true for the other metrics, the model is generalizing well.

By default, the logistic regression algorithm classifies those observations for which the probability is > 0.5 as class 1. We can try to find the optimal value of the threshold by analyzing the precision-recall curve.

The method `predict_proba` returns the probability of each observation belonging to class 0 in the first column and to class 1 in the second column:


```python
y_scores_lg = lg.predict_proba(X_train_scaled)
y_scores_lg
```




    array([[0.19374224, 0.80625776],
           [0.14200443, 0.85799557],
           [0.55913056, 0.44086944],
           ...,
           [0.92606921, 0.07393079],
           [0.56037455, 0.43962545],
           [0.2195274 , 0.7804726 ]])



We can input the probabilities for class 1 together with the true labels to calculate precision and recall for different thresholds in the interval [0,1], and then plot precision and recall vs. threshold and precision vs. recall:


```python
# Calculate precision and recall as a function of the threshold
precisions_lg, recalls_lg, thresholds_lg = precision_recall_curve(y_train, y_scores_lg[:,1], pos_label=1)
```


```python
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,4))

# Plot precision and recall vs. threshold
axs[0].plot(thresholds_lg, precisions_lg[:-1], 'b--', label='precision')
axs[0].plot(thresholds_lg, recalls_lg[:-1], 'g:', label = 'recall')
axs[0].set_xlabel('threshold')
axs[0].legend(loc='lower left')
axs[0].grid()

# Plot precision vs. recall
axs[1].plot(recalls_lg[:-1], precisions_lg[:-1], 'r--')
axs[1].set_xlabel('recall')
axs[1].set_ylabel('precision')
axs[1].grid()

plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_117_0.png">
    


From the curves of precision and recall vs. threshold, we conclude that the threshold could be increased from 0.5 to improve precision a little, without sacrificing much recall. We can adopt an optimal value for the threshold as that where precision ~ recall. Let's calculate its value:

The following line of code applies some Numpy methods to calculates the index where the precision and recall curved intersect (actually, where the difference between them crosses zero):


```python
idx = np.argwhere(np.diff(np.sign(recalls_lg[:-1] - precisions_lg[:-1])))
idx
```




    array([[4600],
           [4601]], dtype=int64)



For our purposes, we can say that precision and recall are equal and ~0.83 at index 4601:


```python
recalls_lg[4600:4603] - precisions_lg[4600:4603]
```




    array([ 9.65243504e-05,  0.00000000e+00, -9.65198727e-05])




```python
recalls_lg[4601], precisions_lg[4601]
```




    (0.8331788693234476, 0.8331788693234476)



The corresponding value of the threshold is ~0.64:


```python
optimal_threshold = thresholds_lg[4601]
optimal_threshold
```




    0.6372292352707758



Let's analyze the performance of the model on the training and test sets for the optimized value of the threshold:


```python
y_pred_train = lg.predict_proba(X_train_scaled)
print(classification_report(y_train, y_pred_train[:,1] > optimal_threshold))
calculate_plot_cm(y_train, y_pred_train[:,1] > optimal_threshold)
```

                  precision    recall  f1-score   support
    
               0       0.69      0.69      0.69      4601
               1       0.83      0.83      0.83      8632
    
        accuracy                           0.78     13233
       macro avg       0.76      0.76      0.76     13233
    weighted avg       0.78      0.78      0.78     13233
    
    


    
<img src="/assets/images/magic_gamma_ray_telescope/output_127_1.png">
    



```python
y_pred_test = lg.predict_proba(X_test_scaled)
print(classification_report(y_test, y_pred_test[:,1] > optimal_threshold))
calculate_plot_cm(y_test, y_pred_test[:,1] > optimal_threshold)
```

                  precision    recall  f1-score   support
    
               0       0.68      0.68      0.68      1972
               1       0.83      0.83      0.83      3700
    
        accuracy                           0.78      5672
       macro avg       0.75      0.75      0.75      5672
    weighted avg       0.78      0.78      0.78      5672
    
    


    
<img src="/assets/images/magic_gamma_ray_telescope/output_128_1.png">
    


> Applying the optimized threshold, the precision for class 1 is now 0.83 for both train and test sets.

### Coefficients of the logistic regresion and feature importance

In logistic regression the log odds are given as a linear combination of the features.

The log odds are not as easy to interpret as the probability of the odds. The figures below show the behavior of the odds and log odds as a function of the probability `p` of an observation being of class 1.  The log odds have the nice property of being symmetric (actually, anti-symmetric) around zero (`p = 0.5`). 


```python
p = np.linspace(0, 1, endpoint=True, num=100)
odds = p/(1-p)
log_odds = np.log(odds)
```

    C:\Users\dell\AppData\Local\Temp\ipykernel_39232\2581333479.py:2: RuntimeWarning: divide by zero encountered in divide
      odds = p/(1-p)
    C:\Users\dell\AppData\Local\Temp\ipykernel_39232\2581333479.py:3: RuntimeWarning: divide by zero encountered in log
      log_odds = np.log(odds)
    


```python
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,4))

# Plot of odds vs. p
axs[0].plot(p, odds, 'b--')
axs[0].set_xlabel('p(Y=1)')
axs[0].set_ylabel('odds')
axs[0].grid()

# Plot of log odds vs. p
axs[1].plot(p, log_odds, 'r--')
axs[1].set_xlabel('p(Y=1)')
axs[1].set_ylabel('log odds')
axs[1].grid()

plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_133_0.png">
    


We can now examine the log odds and the odds to analyze the importance of the features. 

Let's first retrieve the logistic regression coefficients from the attribute `coef_`:


```python
# Print the coefficients of the logistic regression
cols       = X_train_scaled.columns
coef_lg    = lg.coef_[0]
odds_ratio = np.exp(lg.coef_[0])

# Create a DataFrame to store the data
lg_coeffs_df = pd.DataFrame(columns=['lg_coeffs', 'odds_ratio'], index=cols)
lg_coeffs_df['lg_coeffs'] = coef_lg
lg_coeffs_df['odds_ratio'] = odds_ratio

lg_coeffs_df.sort_values(by = 'lg_coeffs', ascending = False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lg_coeffs</th>
      <th>odds_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>aspect_ratio</th>
      <td>0.430268</td>
      <td>1.537670</td>
    </tr>
    <tr>
      <th>fM3Long</th>
      <td>0.310694</td>
      <td>1.364372</td>
    </tr>
    <tr>
      <th>fAsym</th>
      <td>0.214793</td>
      <td>1.239605</td>
    </tr>
    <tr>
      <th>fConc1</th>
      <td>0.183033</td>
      <td>1.200854</td>
    </tr>
    <tr>
      <th>fM3Trans</th>
      <td>-0.030361</td>
      <td>0.970096</td>
    </tr>
    <tr>
      <th>fDist</th>
      <td>-0.310429</td>
      <td>0.733133</td>
    </tr>
    <tr>
      <th>fAlpha</th>
      <td>-1.272094</td>
      <td>0.280244</td>
    </tr>
  </tbody>
</table>
</div>



Let's take `X1 = aspect_ratio`, the feature with the largest coefficient $$\beta_{\rm ar}$$ = 0.43. This means that for an increase in one unit in `aspect_ratio` (actually, its standardized version) the log odds increase in 0.43. The odds, in turn, grow by a factor  $$\rm{odds(X_1+1)} /  \rm{odds(X_1)} = \exp(\beta_{\rm ar}) \sim$$ 1.54.

If we consider now `X7 = fAlpha`, an increase in one unit in the (standardized) value of this feature causes to log odds to decrease 1.27 times.  The odds, in turn, decrease by a factor  $$\rm{odds(X_7+1)} /  \rm{odds(X_7)} = \exp(\beta_{\rm \alpha}) \sim$$ 0.28 .

## Model 2: Logistic regression with PCA

We can try a different approach to the issue of multicolinearity: performing a Principal Components Analysis (PCA) on the data.

Let's use PCA to obtain new features as linear combinations of the original ones, scale them, and fit a logistic regression.

Define the features and target variable, and split into training and tes sets:


```python
X = data.drop(columns=['class', 'class_encoded'])
Y = data['class_encoded']
```


```python
random_state     = 1  # fixed for reproducibility across runs
test_train_ratio = 0.3
X_train, X_test, y_train, y_test = train_test_split(X, Y, 
                                                    test_size = test_train_ratio, 
                                                    random_state = random_state, 
                                                    stratify = Y)
```

Now, standardize the data:


```python
# Initialization of the scaler
std_sc = StandardScaler(with_mean=True, with_std=True)

# Fit_transform on training data
X_train_scaled = std_sc.fit_transform(X_train)
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)

# Transform on test data
X_test_scaled = std_sc.transform(X_test)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
```

### Principal Components Analysis

Let's now perform the PCA on the training set:


```python
# Defining the number of principal components to generate 
n = X_train_scaled.shape[1] # keep all components

# Finding principal components for the data
pca = PCA(n_components=n, random_state=1)
#X_train_scaled_pca = pd.DataFrame(pca.fit_transform(X_train_scaled), columns=X_train_scaled.columns)
X_train_scaled_pca = pca.fit_transform(X_train_scaled)

#The percentage of variance explained by each principal component
explained_var = pca.explained_variance_ratio_
```

We can plot the cumulative explained variance as a function of the number of principal components:


```python
plt.figure(figsize = (5,5))
plt.plot(range(1,n+1), pca.explained_variance_ratio_.cumsum(), marker = 'o', linestyle = '--')
plt.xlabel("Number of Principal Components")
plt.ylabel("Cumulative Explained Variance")
plt.grid()
plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_149_0.png">
    


The first two principal components account for ~58% of the variance in the training set, three components account for ~68% of the variance.

Each principal component is a linear combination of the features. Let's take a look at the coefficients of the linear combinations:  


```python
pc_comps = ['PC'+ str(i) for i in range(1, n+1)]  
data_pca = pd.DataFrame(np.round(pca.components_,2),index=pc_comps,columns=X_train_scaled.columns)
data_pca.T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PC1</th>
      <th>PC2</th>
      <th>PC3</th>
      <th>PC4</th>
      <th>PC5</th>
      <th>PC6</th>
      <th>PC7</th>
      <th>PC8</th>
      <th>PC9</th>
      <th>PC10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fLength</th>
      <td>0.41</td>
      <td>0.23</td>
      <td>-0.01</td>
      <td>0.03</td>
      <td>0.12</td>
      <td>0.02</td>
      <td>0.43</td>
      <td>0.76</td>
      <td>-0.10</td>
      <td>-0.02</td>
    </tr>
    <tr>
      <th>fWidth</th>
      <td>0.40</td>
      <td>0.25</td>
      <td>0.17</td>
      <td>0.07</td>
      <td>0.03</td>
      <td>0.15</td>
      <td>0.51</td>
      <td>-0.53</td>
      <td>0.44</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>fSize</th>
      <td>0.45</td>
      <td>-0.09</td>
      <td>0.07</td>
      <td>0.05</td>
      <td>0.01</td>
      <td>0.04</td>
      <td>0.01</td>
      <td>-0.33</td>
      <td>-0.81</td>
      <td>-0.11</td>
    </tr>
    <tr>
      <th>fConc</th>
      <td>-0.44</td>
      <td>0.19</td>
      <td>-0.15</td>
      <td>-0.09</td>
      <td>0.16</td>
      <td>0.12</td>
      <td>0.33</td>
      <td>-0.07</td>
      <td>-0.14</td>
      <td>-0.75</td>
    </tr>
    <tr>
      <th>fConc1</th>
      <td>-0.43</td>
      <td>0.20</td>
      <td>-0.16</td>
      <td>-0.10</td>
      <td>0.19</td>
      <td>0.13</td>
      <td>0.39</td>
      <td>-0.11</td>
      <td>-0.31</td>
      <td>0.65</td>
    </tr>
    <tr>
      <th>fAsym</th>
      <td>-0.15</td>
      <td>-0.48</td>
      <td>0.42</td>
      <td>0.13</td>
      <td>-0.11</td>
      <td>0.71</td>
      <td>0.14</td>
      <td>0.14</td>
      <td>-0.01</td>
      <td>-0.00</td>
    </tr>
    <tr>
      <th>fM3Long</th>
      <td>0.01</td>
      <td>-0.59</td>
      <td>0.07</td>
      <td>0.02</td>
      <td>0.67</td>
      <td>-0.37</td>
      <td>0.22</td>
      <td>-0.03</td>
      <td>0.09</td>
      <td>-0.00</td>
    </tr>
    <tr>
      <th>fM3Trans</th>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.47</td>
      <td>-0.88</td>
      <td>0.01</td>
      <td>-0.06</td>
      <td>-0.03</td>
      <td>0.02</td>
      <td>-0.02</td>
      <td>-0.00</td>
    </tr>
    <tr>
      <th>fAlpha</th>
      <td>-0.09</td>
      <td>0.46</td>
      <td>0.52</td>
      <td>0.32</td>
      <td>0.52</td>
      <td>0.08</td>
      <td>-0.36</td>
      <td>0.02</td>
      <td>-0.04</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>fDist</th>
      <td>0.26</td>
      <td>-0.00</td>
      <td>-0.51</td>
      <td>-0.29</td>
      <td>0.44</td>
      <td>0.54</td>
      <td>-0.31</td>
      <td>-0.02</td>
      <td>0.12</td>
      <td>0.01</td>
    </tr>
  </tbody>
</table>
</div>



- `PC1` has significant positive contributions from `fLenght`, `fWidth` and `fSize`, and large negative contributions from `fConc` and `fConc1`.
- The largest coefficients in `PC2` correspond to `fM3Long`, `fAsym` (both negative) and `fAlpha` (positive).
- `PC3` has large positive coefficients for `fAlpha`, `fM3Trans` and `fAsym`, and negative for `fDist`.

We can plot the training data in the PC1, PC2 plane, and in the 3D PC1, PC2, PC3  space:  


```python
XY_train_scaled_pca_df = pd.DataFrame(data=X_train_scaled_pca, columns=pc_comps)
XY_train_scaled_pca_df['class_encoded'] = y_train.reset_index(drop=True) 
```


```python
fig, axs = plt.subplots()
sns.scatterplot(data=XY_train_scaled_pca_df, x='PC1', y='PC2', hue='class_encoded', alpha=0.25, ax=axs)
sns.move_legend(axs, loc="upper left", title='actual class', frameon=False)
plt.grid()
plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_156_0.png">
    


In the PC1-PC2 plane most of the class 1 observations are concentrated towards the bottom left quadrant of the first plot. There are also class 0 observations in this region, and there's also a tail of class 0 events extending towards large values of PC1 and PC2.

Apply the PC decomposition to the test set:


```python
X_train_scaled_pca = pd.DataFrame(data=X_train_scaled_pca, columns=pc_comps) # convert to DataFrame
X_test_scaled_pca  = pd.DataFrame(pca.transform(X_test_scaled), columns=pc_comps)
```

### Logistic regression on PCA 

Finally, let's fit the logistic regression and check the performance on the training and test sets:


```python
# Fitting a logistic regression model
penalty_lg = 'l2'
lg_pca     = LogisticRegression(penalty = penalty_lg)
lg_pca.fit(X_train_scaled_pca, y_train)
```




<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div>




```python
# Checking the performance on the training data
#%matplotlib inline
y_pred_train_pca = lg_pca.predict(X_train_scaled_pca)
print(classification_report(y_train, y_pred_train_pca))
calculate_plot_cm(y_train, y_pred_train_pca)
```

                  precision    recall  f1-score   support
    
               0       0.76      0.59      0.66      4601
               1       0.81      0.90      0.85      8632
    
        accuracy                           0.79     13233
       macro avg       0.78      0.75      0.76     13233
    weighted avg       0.79      0.79      0.79     13233
    
    


    
<img src="/assets/images/magic_gamma_ray_telescope/output_163_1.png">
    



```python
# Checking the performance on the test data
y_pred_test_pca = lg_pca.predict(X_test_scaled_pca)
print(classification_report(y_test, y_pred_test_pca))
calculate_plot_cm(y_test, y_pred_test_pca)
```

                  precision    recall  f1-score   support
    
               0       0.75      0.59      0.66      1972
               1       0.81      0.90      0.85      3700
    
        accuracy                           0.79      5672
       macro avg       0.78      0.74      0.76      5672
    weighted avg       0.79      0.79      0.78      5672
    
    


    
<img src="/assets/images/magic_gamma_ray_telescope/output_164_1.png">
    


> The precision for class 1 is 0.81, basically the same as in in the previous model.

We can take a look at how the test data points are distributed in the PC1-PC2 plane according to their true and predicted class, and also at the distribution on this plane of the correctly and incorrectly classified data.

We can also plot the projection of the decision boundary in the PC1-PC2 plane - that is, when the coefficients of the logistic regression for all other PCA components are set to zero. Recall that in logistic regression, the probability of an observation being assigned to class 1 is given by

<center>$$ p(Y=1) = \dfrac{1}{1+\exp{(-\beta_i X_i)}}$$. </center>

For a classification threshold of $$p(Y=1) = 0.5$$, the decision boundary is the hyperplane $$\beta_i X_i =0$$. Those data points for which $$\beta_i X_i > 0$$ have - $$p(Y=1) > 0.5$$ and are classified as class 1, and those for which $$\beta_i X_i < 0$$ have $$p(Y=1) < 0.5$$ and are classified as class 0.

Restricted to the ($$X_1$$, $$X_2$$) plane, the decision boundary can be written as 

<center>$$\beta_0 + \beta_1 X_1 + \beta_2 X_2 = 0$$. </center>




```python
# Define the decision boundary in the PC1-PC2 plane
x1    = np.arange(-6, 12, 0.2)
beta1 = lg_pca.coef_[0][0]
beta2 = lg_pca.coef_[0][1]
beta0 = lg_pca.intercept_[0]
x2 = -(beta1/beta2)*x1 - (beta0/beta2)
```


```python
# Some auxiliary DatFrames for plotting purposes
XY_test_scaled_pca_df = pd.DataFrame(data=X_test_scaled_pca.values, columns=pc_comps)
XY_test_scaled_pca_df['class_encoded'] = y_test.reset_index(drop=True) 
XY_test_scaled_pca_df['class_pred']    = y_pred_test_pca
XY_test_scaled_pca_df['correct_pred']  = XY_test_scaled_pca_df['class_pred'] == XY_test_scaled_pca_df['class_encoded']
```


```python
# Plots
    
fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14,4))

# Target variable in the test set in the PC1-PC2 plane, colored by actual class
sns.scatterplot(data=XY_test_scaled_pca_df, x='PC1', y='PC2', hue='class_encoded', alpha=0.25, ax=axs[0])
sns.move_legend(axs[0], "upper left", title='Actual class', frameon=False, fontsize=9, title_fontsize=9) # tune legend
axs[0].set_xlim([-5,10])

# Target variable in the test set in the PC1-PC2 plane, colored by predicted class
# The line is the logistic regression decision boundary in the PC1-PC2 plane
sns.scatterplot(data=XY_test_scaled_pca_df, x='PC1', y='PC2', hue='class_pred', alpha=0.25, ax=axs[1])
sns.lineplot(x=x1, y=x2, ax=axs[1], linestyle='--', color='k', label='') # prediction boundary
sns.move_legend(axs[1], "upper left", title='Predicted class', frameon=False, fontsize=9, title_fontsize=9) # tune legend
axs[1].set_xlim([-5,10])

# Target variable in the test set in the PC1-PC2 plane.
# Data classified correctly are displayed as green stars, data classified incorrectly are displayed as red crosses 
# The line is the logistic regression decision boundary in the PC1-PC2 plane
sns.scatterplot(data=XY_test_scaled_pca_df, x='PC1', y='PC2', hue='correct_pred', 
                alpha=0.5, palette={True:'g', False:'r' }, ax=axs[2], style='correct_pred', markers={True:'*', False:'X' })
sns.lineplot(x=x1, y=x2, ax=axs[2], linestyle='--', color='k', label='') # prediction boundary
sns.move_legend(axs[2], "upper left", title='actual=predicted', frameon=False, fontsize=9, title_fontsize=9) # tune legend
axs[2].set_xlim([-5,10])

plt.show()
```


    
<img src="/assets/images/magic_gamma_ray_telescope/output_169_0.png">
    


The projected decision boundary captures the tail of class 0 observations. Remember that we are not looking at the full picture since the logistic regression was fit with all the principal components, not just these two.  
